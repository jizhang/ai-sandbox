{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "datafile = os.path.join(os.getenv('GEEKTIME_AI_COURSE_DATA'), 'mr_fujino')\n",
    "documents = SimpleDirectoryReader(datafile).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/examples/vector_stores/SimpleIndexDemo/\n",
    "index.set_index_id('vector_index')\n",
    "index.storage_context.persist('./storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir='storage')\n",
    "loaded_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅先生去仙台学习医学。\n"
     ]
    }
   ],
   "source": [
    "query_engine = loaded_index.as_query_engine()\n",
    "# response = query_engine.query('鲁迅先生在日本学习医学的老师是谁？')\n",
    "response = query_engine.query('鲁迅先生去哪里学的医学？')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅先生在日本学习医学的老师是藤野先生。\n"
     ]
    }
   ],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/module_guides/models/prompts/usage_pattern/#defining-a-custom-prompt\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = (\n",
    "    'Context information is below. \\n'\n",
    "    '------------------------------\\n'\n",
    "    '{context_str}\\n'\n",
    "    '------------------------------\\n'\n",
    "    'Given the context information and not prior knowledge, '\n",
    "    'answer the question: {query_str}\\n'\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "query_engine = loaded_index.as_query_engine(text_qa_template=qa_template)\n",
    "response = query_engine.query('鲁迅先生在日本学习医学的老师是谁？')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "template = (\n",
    "    '下面的“我”指的是鲁迅先生\\n'\n",
    "    '-------------\\n'\n",
    "    '{context_str}\\n'\n",
    "    '-------------\\n'\n",
    "    '根据这些信息，请回答问题：{query_str}\\n'\n",
    "    '如果你不知道的话，请回答不知道\\n'\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "retriever = loaded_index.as_retriever()\n",
    "synth = get_response_synthesizer(text_qa_template=qa_template)\n",
    "query_engine = RetrieverQueryEngine(retriever, synth)\n",
    "# response = query_engine.query('请问林黛玉和贾宝玉是什么关系？')\n",
    "response = query_engine.query('鲁迅在哪儿学的医？')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/examples/index_structs/doc_summary/DocSummary/\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from llama_index.core import get_response_synthesizer, SummaryIndex\n",
    "from llama_index.core.node_parser import LangchainNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "text_splitter = SpacyTextSplitter(pipeline='zh_core_web_sm', chunk_size=2048)\n",
    "node_parser = LangchainNodeParser(text_splitter)\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.environ['OPENAI_API_BASE'],\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    temperature=0, \n",
    "    model='gpt-4o-mini',\n",
    "    max_tokens=1024,\n",
    ")\n",
    "# llm = OpenAI(temperature=0, model='gpt-4o-mini')\n",
    "response_synthesizer = get_response_synthesizer(response_mode='tree_summarize')\n",
    "\n",
    "list_index = SummaryIndex.from_documents(\n",
    "    documents, \n",
    "    llm=llm, \n",
    "    transformations=[node_parser],\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = list_index.as_query_engine()\n",
    "response = query_engine.query('下面鲁迅先生以第一人称‘我’写的内容，请你用中文总结一下:')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* [ImageReader](https://docs.llamaindex.ai/en/stable/api_reference/readers/file/#llama_index.readers.file.ImageReader)\n",
    "* Install PyTorch 2.5.1\n",
    "* Receipt OCR & query."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-sandbox-aoUc62G5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
